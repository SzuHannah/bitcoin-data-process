# Architecture design

[Figure 4](#fig4) illustrates the architecture design of the whole parser, file, and database system we used to decode the Bitcoin blockchain ledger into a simple wallet graph for analysis. The Blockchain Parser was Python-based, and it decodes the blockchain. The blockchain is encoded in bytes and split into multiple .dat files. Each user in the ledger network retains a copy of the files. The Parser converts bytes into readable Json form. Each block generates one Json file that contains information such as block height, block timestamp, block difficulty, number of transactions within the block, and detailed transaction records.&#x20;

Further, each JSON is split into multiple CSV files by the CSV Parser, and we processed the JSONs (i.e. blocks) in batches. For one batch, there were thousands of blocks. This specific batch would result in: one blocks.csv that contained the information of all blocks in the batch; thousands of transactions.csvs and addresses.csvs - every block would be split into one transactions.csv and one addresses.csv, while the former recorded all transactions included in the block, the latter recorded all addresses appeared in the block. The resulting CSVs were further inserted into a SQLite database.&#x20;

The addresses.csvs were uniquely imported into the database such that we created an address-ID lookup table. Originally, addresses were represented in long strings within transactions. Thus, we assigned address IDs to replace the address strings for computation efficiency. As we were not interested in the all-time transaction pattern, we let transaction tables inherit the timestamp information from block tables for later time-range filtering.

![Figure 4 Architechture design](../.gitbook/assets/Architecture-of-the-system)

The address-ID lookup table and transaction tables with mapped address IDs were then exported. We built an Edge-list Parser with Python to read in transaction tables and created edge lists that represent the spent-together history of addresses. That is, there is an edge between address ID = 1 and address ID = 2 if they can be spent together; thus, every transaction can produce one edge list. The Address Clusterizer then loaded the address-ID lookup table and streamed in the edge-lists to generate an addressID-walletID lookup table. The Address Clusterizer was implemented with Weighted Quick Union with Path Compression (WQUPC) algorithm that will be described in the Algorithm section.

After the addressID-walletID lookup table was generated, we inserted it back into the SQLite database. Further, we mutated a walletID column and mapped the walletIDs for each transaction table. Then, the transaction tables were exported and imported into a Neo4j graph database. Every row of the transaction tables was represented in a walletID-transactionID-walletID graph illustrated in [Figure 2](#fig2). We leveraged the built-in graph database commands to merge the inputs and outputs into one edge called “sent” using the heuristic described in [Figure 3](#fig3). Finally, this simplified walletID-walletID graph was used for analysis.
